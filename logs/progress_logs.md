# autolang Progress Logs

By Lyons / fawnium

These are my personal progress logs that I am writing during the development of autolang. They are more stream-of-conscioussness than a formal documentation of the project. They are mainly intended to give an informal insight into my development process for the interested reader, and also to help me organise my thoughts so I can develop more efficiently. I wrote them in conjunction
with the code, and didn't re-draft them after the initial writing, so don't expect them to be good!

## 30/08/2025 - Log #0

I decided it would be a good idea to create a log of how the development of autolang is going, so that it is not just documented implicitly in the code. I have already written quite a lot from when I started in May/June until now, but it will be hard to remember all of this in detail, so I will simply summarise:

I first implemented minimal classes to simulate DFAs, NFAs, PDAs, and TMs. The only major function of each of these thus far is to take an input string, simulate the respective machine processing it, and returning acceptance value. The TM also returns the tape at time of halting as well as a boolean. I then realised that the specific formatting for the transition functions of each machine is quite nuanced and complicated, and varies in subtle ways for different machine types. So I refactored the transition error-checking into separate classes which only validate the data structures and don't do any simulation. The separation here is still not as clean as I would like - for instance the lists of states and alphabet must still be passed separately to the transition function and must be passed to both the transition object and the automata object itself. This feels quite redundant, and I think a better solution would be to automatically extract the states and alphabet from the transition function, but this would involve more thought about handling errors and edge cases. As it does not affect the code's function, it is not a major priority, but this will likely need another refactor later. I expect much of the existing code will need to be drastically changed or removed entirely eventually. For example, the existing machines can process input words, but do not return any logs or demonstrate step-by-step computation. This will need to change to allow nice visualisations or illustrate specific computation steps for education. The potential solutions I can think of are either: keeping the existing classes but embedding extra lines and function calls to the frontend; or building entirely new classes using what I've learned, and having two copies of each machine in the source code - one for purely returning acceptance, and one for more detailed user explanation which is more complex and includes the frontend integration. All of this will probably be done later down the line. With the basic machines already implemented, my current next step is adding regex/language features which work in tandem with the automata. I am currently working on the regex-NFA-DFA pipeline, which is still in the early stages. I have written a parser for simply validating the syntax of an input regex. Now I need to create another parser to iteratively construct the corresponding NFA itself. I considered Thompson's Construction which appears to be the canonical way to do this conversion. What I would like to instead do is implement a construction that is closer in spirit to the theoretical method/proof which appears in notes/textbooks, that is more intended for illustration and to be done with pen and paper. I believe this is spiritually the same as Thompson's construction under the hood, but I would like to do something closer to what my personal thought process was when learning the theory, and arrive on something that is not necessarily the most performant or canonical, but is reflective of how I came to understand the construction myself, and will hopefully to easier for students to directly connect to the theory they are learning. Perhaps I will 'accidentally' reproduce Thompson anyway...

After regex-NFA, the next natural step is NFA-DFA using the standard powerset construction, and perhaps with further state minimisation. I expect this will not be as challenging, since it more directly follows the theory, and should not involve as much parsing/lexical analysis. 

Below I list the remaining long-term goals of the project that I have thus far been thinking about. These may change, but I need to make them concrete by writing them here so I have a roadmap in mind during development:

- Finish regex-NFA-DFA
- Do similar pipeline for CFG-PDA
- Add more miscellaneous grammar features, such as converting to Chomsky Normal Form and other macros/preprocessing algorithms
- Add more (sub)classes of automata, such as multi-tape TMs and similar variations. This will likely require polymorphism, and/or further serious considerations about the overall project structure
- Implement visuals of the machines. I already experimented with drawing automata using `networkx`, but it grew very complex with edge-cases and creating nice, readable layouts. Handling arbitary-length edge labels, overlapping edges, nondeterministic- and epsilon- transitions, and general graph-readability are all hard to formalise in 
code, and will take more time to do well than I have right now. I abandoned the visualisation for the time being, as I wanted to focus on getting the backend working first.
- Further develop the frontend, such as having an interactive display of the automata, which allows adding/removing states and transitions, and a live playback of computation, which will for example highlight the current state(s) with different colours, and perhaps include some animations later. I know there are libraries to do this natively in python, but in the past I found them to be quite janky and 'ugly'. I suspect the best strategy is to write the frontend in JavaScript, but to do that I first 
need to learn JavaScript.
- Go back and re-implement several features using the above instead of native python. For example, the parser(s) for handling regex is just done with a separate python class now, but I would like to do this with autolang's own PDA feature which already exists. While regular expressions describe regular languages, the language of regular expressions *themselves* is context-free. Therefore since this is exactly what PDAs are supposed to be for, I think keeping the whole project as self-contained as possible, and recursively using some parts of the code to help other parts, would be a nice 'meta-level' flare, and really highlight how powerful these state machines are.
- Ultimate Goal: write a 'direct-to-TM' quasi-compiler. This will take either a subset of real python or a minimal custom DSL, convert it to a TM transition table in numerous steps, and then execute the code directly on a virtual Turing Machine. This is of course very ambitious, and I don't know how far I will get with this. I will need 
to sequentally design various intermediate steps to parse and process the code, build ASTs, and I aim to use autolang's DFAs/PDAs to do this as much as possible. I will then need to design a reasonable computer architecture that logically partitions the TM tape into input, memory, etc, and somehow create a library of macros that converts quasi-assembly instructions into entries in the TM transition table. I imagine this will be easier to do on a multi-tape machine, which is then converted to a single-tape 
as the final compilation step.

## 30/08/2025 - Log #1

Today the goal is to make progres on regex-NFA. I will first finish writing some unit tests for the regex syntax validation. Hopefully after that I will finally be ready to do the construction itself. I need to make a `GNFA` class, which allows edges to be labelled by arbitrary strings instead of just letters in the alphabet or epsilon. The algorithm will work by doing the following:

- start with a GNFA with only a start and accept state, and one edge labelled by the whole regex.
- iterate through the edges, find the first one with a non-trivial/non-atomic label, and parse the label.
- when parsing edge label, find the first top-level operation, and modify the GNFA according to the respective rule from the theoretical proof - e.g. for union `+`, delete the initial edge and make two new edges labelled by the child-regexes.
- stop when all labels are atomic, meaning hopefully we should have a valid (non-G)NFA!
After this, I will write more tests to ensure the resulting NFA is correct. These shouldn't be very hard - it should simply be a matter of coming up with some example regexes, and checking the language of the NFA matches the actual language of the input regex, the latter being generated using existing functions from `utils.py`

Finished tests, adding concat, and the GNFA class which handles construction logic. Still need to implement the parser that decides what operation to eliminate.

## 31/08/2025 - Log #2
Today the aim is to implement the parser which performs an elementary elimination on a regex string. After that, the entire regex-NFA construction should be complete. The parser needs to decide which of (+, ., *) is the highest-precedence operator in the regex, ensuring it remembers how deep it currently is in terms of brackets. It must only eliminate a top-level operation, i.e. outside any grouped subexpressions. After that, it should return a tuple consisting of which operator is being eliminated (`None` if regex is primitive), as well as the resulting smaller regex(es) to be used as labels for the new GNFA edges. For both union + and concat ., two regexes will be returned (the operands on each side of the operator), whereas for star * only one is returned, since * only acts on a single atom. I imagine this will be quite challenging to do correctly.

If there is time, I will also write some unit tests for the GNFA class, separate to the tests for the entire regex conversion. I already did some tests for adding explicit concat yesterday, but it is likely many more will need to be added accross the existing code. For the time being, as long as the languages match, I think it is safe to assume the entire regex-NFA conversion works correctly. We will see once the code is actually implemented...

## 03/09/2025 - Log #3

I have made some progress in the last few days, but it has been slower than expected, due to other time commitments and complications in the implementation. The GNFA class seems to working fine now, and the small amount of tests all ran OK. Today the regex elimination parser will be completed. I already wrote a method to strip outer brackets. 
These arise in a regex substring if that substring was originally grouped in the parent expression, but after elimination steps has now been isolated. None of the actual operator elimination methods remove brackets from a string, so this needs to be handled in preprocessing before the core functionality of the parser executes. Otherwise, a regex such as '(a+b)' would be decomposed as '(a' and 'b)', which clearly shouldn't ever happen.

Today I will write the actual elimination method(s) of the parser. This should not actually be too difficult - it doesn't require recursive descent or anything complicated, because all regex strings are assumed to already be syntactically valid at this stage of the pipeline. The only important nuance is keeping track of bracket depth, so that for example, '(a+b)+c' is correctly decomposed as '(a+b)' and 'c', and not as '(a' and 'b)+c'. The other important thing I realised after some thinking and testing, is that it is crucial to always check for union first, then concat, and then star, and not simply return at the first top-level operator of any kind. If this was not done, then for example 'a.b+c' would be incorrectly decomposed as 'a' and 'b+c', instead of the correct 'a.b' and 'c'. This priority of operators is the correct way to capture the Thompson's Construction idea, and accurately reflects the hierarchy of the regex grammar.

This project has really got me thinking about BODMAS/PEMDAS in far more detail than I did when I was first learning algebra and arithmetic back in the day. Things like which operators bind to which terms in an expression, are quite intuitive to a human who can visually scan an entire word or string all at once, but are surprisingly difficult to rigorously formalise in code. I suppose that is precisely why finite state automata (and hence this project) were invented in the first place.
Update: I finished the regex elimination parser, and wrote a wrapper that handles the entire regex-to-nfa pipeline. After a few rudimentary unit tests...it works! I never thought that seeing a simple 'OK' printed to my screen could bring so much joy. I will try to keep these logs professional, but I honestly did not believe I would be able to pull this construction off with this few complications or setbacks. The next step is is to make sure it really works by writing some more robust tests, and then moving on to the DFA construction. I think after that would be a good point to take a step back and think about cleaning up the existing codebase, before moving on to CFGs.

## 07/09/2025 - Log #4

Today the task is to implement the NFA-to-DFA subset construction. I also need to do some more testing of regex-to-NFA, but I will probably do this afterwards because I have been finding all these tests quite tiring and monotonous (but they are important). I have been thinking about how to translate the construction in the proof into code while 
at work, and have already been taking interest in some of the arising subtleties that I will no doubt have to resolve today. For example, in the theory a DFA is just a special case of an NFA, but in my code, they both exist as effectively completely separate sections of code. In the DFA transition function, the outputted value is just a single state string (unlike a list of strings for the NFA). I could similarly have defined it to be a list containing only a single state, which would have been more 
consistent with the nondeterministic classes. I chose not to do so because I figured using a list to contain the state when there is by definition only one, will add additional indexing overhead while extracting the state, hence slightly reducing performance during runtime. I imagine these performance considerations are trivial, but it does make me really think about how to make decisions for or against performance versus clean/consistent code. That got me thinking about polymorphism again - certainly 
according to the theory, it would make sense to refactor the DFA and NFA to be instances of a base 'Automaton' class, and then only implement what strictly differs from the general case. I think this may have some educational benefit, since the code could be more exprssive and more directly demonstrate the precise differences between different automaton models. However, I also have a natural or intuitive aversion to polymorphism, likely in part because I have not really tried it yet, but also because I think it can be easy to over-engineer a complex inheritance hierarchy just for the sake of being 'clever', regardless of whether it meaningfully improves the encapsulation of the code. All the energy I must spend to use by category-theoretic brain to really think about the best way to partition automata functions using inheritance, is energy I am not spending actually writing the code and making it work. And additionally, I will likely not even be able to intuit the best inheritance structure until all of the actual code exists in front of me first. I am of course not opposed to this kind of thinking - pure math is nothing if not categorising classes of complex structures in well-defined and 'pretty' ways - but this is a different context to 'taming' opaque and complex algebras, this is about getting a code that does what is supposed to do however it can, and then thinking about restructuring and making it pretty later. I feel I am trying to think about everything at once and not making material progress anywhere. All this leads me to just stop thinking about polymorphism, and try to focus on each task in the roadmap as it comes. There will very likely be a more appropriate time to think about inheritance later down the line, and as I said in a previous log, finishing the subset construction is a natural stopping point to think about the overall architecture again. Therefore 
the most crucial thing in any case is doing the subset construction today!

Regarding implementing the subset construction, I will have to think carefully about how to build the DFA step by step. The intellectually easiest way would be to pre-populate with all possible subsets, then add the transitions, then delete the states that are not used. But this would be extremely memory-hungry for any NFA with a moderate number of states, since the growth is exponential. Therefore a better idea is some kind of 'lazy construction' where subsets are only added when strictly mandated by a transition. This means I will need to try and focus on the individual methods while having some idea of how they work together, before actually seeing how they work together, e.g. correctly generating the epsilon closure of a transition before even having an object for it to operate on. This is the eternal paradox of needing to make the parts before having the whole, while simultaneously needing to understand the whole to make the parts, and it was this kind of paradox that caused me problems with the recursive descent parser and other areas before. But this is something that needs to be done, and it is very rewarding when it all eventually works together all at once. I believe Feynman had some quote about nobody really understanding quantum mechanics, which I think also applies to recursive ideas in programming. You don't really have to understand it (if anyone even 
knows what true understanding is), so long as you can leverage it to achieve your goal and have a good working knowledge of the tools at your disposal. That being said, gaining more understanding is always better, and I feel that I have been gaining a lot of deeper understanding since starting this project. I hope that feeling is balanced more towards reality than delusion, but if it is more delusion, it has at least got me this far, and the code seems to be doing what it's supposed to. 

Update: lazy subset construction now seems like not only a better idea, but completely essential for this code to have any general-use viability. If the input NFA has 30 states, then the upper bound for the number of DFA states is already over a billion. A billion states is manageable on most hardware, but it will only get much worse from there, and certainly 30 input states is a reasonably small number that could easily get passed during runtime. Therefore lazy construction is the only way. But then my only concern is that I may have over-engineered the `TransitionDFA` error checks. It must have a transition for every possible state, but I'm not yet sure whether this will flag subset-states that technically should be members, but are never actually reachable by an input word. With lazy construction, it *should* be allowed to states that are not reachable. I think it is more likely than not to be ok as-is, because the finished DFA doesn't really 'care' about the specific NFA states from which it was built, so I will proceed with caution but not refactor the Transition structs yet. The long-term solution I had planned for this is to extract the states and alphabet lists from the transition dict directly, instead of passing them independently - this would also simplify a lot of the error handling and yield better encapsulation. But that would require a huge refactor because virtually all relevant function signatures in the project would need to be modified. As I expected, my past bad decisions are catching up with me despite my best efforts. But I said I would finish the subet construction before any refactor, so I have to stick with that. If I can't stick with a bad decision that was made in good faith, I will never get anything done. But I am definitely going to hold off on anything to do with CFGs or further features until I'm a lot more happy with the existing code's design - the first version will certainly go up on GitHub before anything else major is added.

Update #2: The NFA-DFA constructor class is now finished (I think), but I haven't ran or tested it. I followed Sipser and a pen-and-paper construction found at `https://www.youtube.com/watch?v=jMxuL4Xzi_A` to try and ensure the construction was followed correctly, but there was still a lot of re-ordering steps to make it logical and reasonably performant inside python. It may not work properly right now. However, I think now is a good time to do a big refactor as the DFA construction highlighted some formatting/data encoding inconsistencies that need to be resolved sooner than expected to avoid more technical debt. This means I will likely have to rewrite `ConstructDFA` to align with the rest of the project as it is being updated, but otherwise I would have to also rewrite the tests, so it seems pointless to do the tests now when most of the code will be torn down anyway. Either way I will find out if it works at some point, but this way I am reducing the amount of rewrites. At least now the code 
is written and I'm confident it 'mostly' works - if it doesn't this will be revealed in testing. Now I need to finish the tests for regex-NFA since they were already started, and go all the way back and rewrite 'backend/machines'

## 10/09/2025 - Log #5

I have already begun rewriting the transition wrapper classes, and modifying the automata objects accordingly. It is tricky to ensure that everything will still be passed to the automata objects as it was before, given that the initialisation arguments are being modified. The existing unit tests will likely also have to be rewritten for the same reason, but I think it is a change that is worth doing. After the rewrite, the lists of states and alphabet letters will no longer be passed as separate arguments. 
Instead, they will be directly extracted from the transition table. In my view this is a much better design choice, because there is no possible case where for example an automaton should have an internal state that is not listed in the transition function, since such a state could never actually be reached during computation. The same is true for alphabets - if a letter cannot be read by the transition function, it might as well not be in the alphabet. With this change, less information is required as input, which yields a cleaner code architecture with better encapsulation.
After this refactor, I need to go back and check the regex-DFA construction is still working. Then the only thing left is to ensure all the tests are reasonably robust before deploying version 1.0. The current plan for v1.0's features is the following: working DFAs, NFAs, PDAs, and TMs; a working regex-DFA pipeline; some examples of how to use each feature and a README; and finally the appropriate test files. That is everything for the first version. v1.1 (or whatever it'll be called) will then include some minimal visualisation - namely printing transition tables and drawing static transition diagrams. The CFG stuff will come after that. I feel I am now at the stage that mandates more detailed thinking about the versioning and overall roadmap, but I still need to focus on just getting the first version out in public. That will be the first major breather where a step back can be taken to consider the later steps.

Update: I have uncovered a subtle challenge with the new input scheme when it comes to TransitionTM. It will not be possibly to independently extract the input and tape alphabets, since the transition function does not have an intrinsic way to distinguish between letters that are and are not allowed as input. This is because unlike the PDA case, where the input and stack letters do not overlap within the data structure, the TM transition effectively works with the input and tape all pooled together during 
compute. Hence it seems the power of generality which Turing machines have, is also the reason they are difficult to implement consistently with the rest of the project. I cannot see a rigorous way of separating the input and tape alphabets without the user explicitly passing them in their entirety, which is precisely what the refactor was meant to avoid. In practice this may not be a huge hurdle - the most crucial thing is that the reserved blank letter '_' is forbidden in the input alphabet, but other than that I think in most real cases the input and tape alphabets will mostly* agree. This is a difficult problem though. The easiest solution for now is to simply always assume both alphabets agree excluding the blank letter, and handle the separation in a later version. This of course means the TM implementation does not have full generality and does not completely align correctly with the theory. But the TMs are not a main feature of v1.0, and are mainly there for demonstration and to signal the later ambitions of the project. I will have to remember to make a note of this in the README.

Update 2: It is also harder than expected to handle the accept and reject states of the TM. These should be included in the list of states according to the theoretical model, but are allowed to behave slightly differently, since they don't allow outgoing transitions. I'm also conflicted about whether to include default values for the start and accept state - if I do, these names may conflict with user-intended names in unexpected ways, but if I don't then the user has more responsibility to correctly identify the halting states, and that requires more complex input handling. Either way it is a non-trivial design problem. There is also the question of whether we should actually enforce halting states being listed in the transition function in the first place - if there is no way to enter a halting state for any input, then is this a user mistake, or did they intend to have a machine that can't halt by design? This is a lot to think about and is quite nuanced. I think these kind of questions shouldn't be thought about too much at this stage as it's slowing down progress, and the focus of v1.0 is on DFAs and NFAs anyway. Likely the best strategy will be revealed when I'm writing concrete example uses of the code later today, anyway. In any case I don't think it is logically possible to construct the TM purely from the transition function alone - there is simply not enough information encoded in it for such a complex machine.

Update 3: I am now pretty sure the refactor is finished and should keep everything working. I have not however updated the unit tests. Now I think what is important is to write some clear examples to show users how to interact with the code. Potential problems will come up if the examples fail, so if that happens, then is the right time to redesign the unit tests, in tandem with the concrete examples. I will try as much as possible to use examples directly from Sipser to have an easy and canonical reference.

## 12/09/2025 - Log #6

I have discovered a subtle and tricky bug in the nfa construction, which was exposed when testing with input '(0+1)0*'. The elimination parser needs to trim enclosing brackets each time it's passed a regex, otherwise it would not find any top-level operator for '(0+1)' for example. On the other hand, it needs to match the exact original regex when attempting to remove the corresponding edge. Therefore it needs some way to simultaneously omit arbitrarily many layers of brackets, while still remembering how many layers were there so that it can find the right edge to delete. The bug emerged because it correctly split the input into '(0+1)' and '0*', but then it turned the former into just '0+1', and then tried to find an edge labelled '0+1.0*' instead of '(0+1).0*', which was the intended deletion target. This was a nuanced problem that I did not expect, and 
it seemed to emerge from the implementation in a way that was not obviously connected to the theoretical construction. It is remarkable how many small, simple steps the human brain subconsciously omits when thinking about interpereting a string of symbols on a page. Perhaps it is because it is a skill learned so early in life and is so intuitive, which makes the study of lexical analysis all the more interesting. 

Much else has been completed including many example usage files, but I don't care to go into detail as it is already quite late. I just want to fix the edge removal bug though - I think the easiest solution is storing a copy of the edge before passing to the parser, rather than doing something clever like returning the exact number of brackets.

## 14/09/2025 - Log #7

As of today I am finished with my part-time job, so now I should have much more time to focus on autolang which is very exciting. I did a lot yesterday which I forgot to log. Most importantly I fixed the bug in the DFA subset construction by standardising subset representations as ordered tuples, which attains the best of both worlds by being deterministic and ensuring equivalent subsets with different orderings are still identified as equal, while ensuring subset representations are well-behaved and can be stored in a parent set via hashing. I previously didn't know that trying to put a set inside another set will cause problems in python, but that is both unsurprising and interesting. The example files for the main intended features are now finished. I have also decided the initial version will be called v0.1.0 - this is better than starting with v1.0, which is now intended to be the fully-fledges library with CFG features etc. Based on the examples I believe the code is working as intended, but of course the test files still have to be written. This will likely take some time to do robustly, so what is most likely is that the initial version will omit the tests which will then be added in a later commit.

Here is everything I need to do before v0.1.0 finally goes public: add a .gitignore file; properly learn how to use git and actually commit the code (I already did this for another project back in 2019 but have forgot everything); write a comprehensive README (this will likely take some time); add visualisation (I also decided this would be important to have in the initial version as it is a core feature); and finally push the code! There are likely some other steps that either I've forgotten or will emerge whilst doing the above, but now we are very close.

## 15/09/2025 - Log #8

We are in the home stretch for releasing v0.1.0, and as usual this is where things start grinding to a halt. I always find that doing the small, technical, bureaucratic details to finalise a project are harder and more time-consuming than the actual project itself, and nothing is different here. I am somehow still having issues with local imports - it seems relative imports are breaking with the `visuals/` folder. In general the code itself is not the problem, but packaging the code and enabling users to actually use it is trickier than expected. I need to make a .toml file and various other python things to get it working, and so I will likely have to do a lot of learning today. The ultimate goal is usability, so users should be able to simply do `pip install autolang` and have it just work, but I think that is still far away right now. The planned installation 
for the first release is by simply cloning the repo from github, and running the code in a more 'manual' way. I think getting this scheme working is more important than the final user case, but in any case getting the import paths correct is crucial. I am also still trying to figure out src layout so I will probably have to go and read the guidance again. This feels like a stupid set of issues to get stuck on instead of the actual automata logic, but that's software development for you I guess.

Update: I think now all the imports the __init__ file are working correctly (although this is about the 5th time I have said that). Now I am working on the transition table formatting for each automaton model. This is a different kind of problem but still interesting - the challenge now is calculating column widths correctly instead of implementing automata compute trees. The DFA table looks great, and now I am doing the NFA table which shouldn't be very different. The PDA will likely require more consideration because the header rows need to be formatted with sub-cells to list the input *and* stack letters, but that is a fun and exciting challenge for later today.

Update 2: The PDA transition table turned out to be harder than expected. Getting the formatting right is a nightmare considering that here there are effectively two different types of columns: the micro columns, which contain the actual cell values; and the macro columns, each of which includes one micro column for every letter in the stack alphabet (and epsilon). Getting this right will take more time and I don't think it is a priority. The TM transition should ironically be easier, since it is deterministic and there is only one alphabet to worry about, so I *will* get that done. It is really interesting, seeing how the theoretical differences between the abtract models translate to different problems and different degrees of complexity when implementing them in code. The DFA is the simplest model, and is also the easiest to implement in code. NFAs are slightly harder due to nondeterminism, but are still quite similar to DFAs. PDAs might actually be the hardest, because not only are they nondeterministic, but they also have two alphabets. It might be tempting to say that TMs are harder because they also technically have two alphabets, but once again they seem to be an outlier: the distinction between the alphabets only really matters when creating the machine, since after that everything just lives on a single tape; and they are deterministic which makes everything substantially easier. This is not really relevant to the progess, just an observation. 

Update 3: I also forgot another interesting observation I noticed. The main problem with the PDA table is that correctly counting the width of cells *and* including the right number of dividers between the cells is actually quite hard. This could be hacked together with some clever 'magic' lines for the DFA and NFA, but with the PDA I had to account for which dividers came from the 'macro' columns, and which for the 'micro' columns. If there was only one alphabet, this can be achieved by just looping through the letters and prepending each with one div, then appending a single div at the end for the outer border. But with two alphabets, you have to be careful with counting the divs - for example if you tried the same thing and prepended both the input *and* stack letters with a div, then you would end up with double divs at the beginning of each new macro column, which is suboptimal. There is definitely a simple way to do this but I just need more time - this is taking me back to counting intersections of subsets by iteratively adding and subtracting. Anyway, the observation is that ironically, this kind of problem seems to feel like a CFG problem. We start with a nonterminal that represents the header, then this can yield a macro nonterminal, which in turn yields the micro columns which terminate to the actual letters. I'm sure it's possible to define an actual grammar for this problem, but it wouldn't be very interesting because it can only generate one word, namely the final column header. While it would definitely be over-engineering to use a PDA to build the PDA table itself, I think it is really interesting how I'm now seeing these connections everywhere. I think this reflects the meta, self-referential theme of the 
project - we are using computers to simulate computers, so of course said computers will be relevant to solving their own problems! 

## 17/09/2025 - Log #9

I made some relaxing progress on the train yesterday and this morning. I am still working on the PDA table, but I think it is now almost done. The PDA table is more dynamic than the other tables, because it calculates an individual width for each column. It might be a good idea to change the other tables to align with this to save space on the screen wherever possible, but I will worry about that later.

## 22/09/2025 - Log #10

Unfortunately I have been suffering from a viral infection the last few days, but that has not stopped me continuing to code, albeit slowly. I am now finally completing the unittests for the project slowly but surely. I am currently rewriting the previous tests that were written before the refactor that changed all of the function signatures, and 
after that I will finish by writing tests for the rest of the files that didn't have any tests before. Unfortunately I haven't been able to run the tests during this process because the old tests (which are now broken) are still in the parent folder, and I can't be bothered moving them out. But once I have rewritten all the old tests I will be able to run them before writing the new tests. This is a little risky as it may result in a large barrage of failures all at once, but I will have to cross that bridge when it comes and fix them one by one. I would rather get all this right before the release, even if it takes more time. The progress is getting painfully slow in this finalisation state as I iron out all the subtleties. I am starting to see why 'crunch time' is so prevalent in software development.

While rewriting the tests I think I spotted another bug in the regex elimination parser, once again due to enclosing brackets. Before, a primitive regex would simply instruct the GNFA to do nothing, since no elimination needs to happen. But this would cause problems for something like '(a)', which is technically primitive, but still needs its brackets 
removed before creating the NFA. The problem was that the brackets were only removed internally in the parser, and the GNFA could not 'see' whether or not any brackets were trimmed. The fix I had for this before was to record the initial regex inside the GNFA before calling the parser. This works for something like '(a*)', but would not work for '(a)*', since this 
would produce an edge '(a)' that would fail to be caught in the next GNFA iteration. The new fix I made is that instead of the parser returning nothing for a primitive regex, it now returns the primitive regex after the brackets are removed, hence allowing it to communicate the removal to the GNFA. Passing an edge with brackets to the final NFA is a terrible idea and will lead to breaks. I believe I the NFA init error checks would catch this, but it is still not acceptable to raise an error, and worse case scenario there is no error, and instead there will be silent unintended behaviour in the NFA, which would be catastrophic. I believe now there shouldn't be more problems with bracket handling, but the communication between the parser and GNFA is quite janky, and could probably do with a rewrite. That is something for a later version.

Update: The 'bug fix' has broken all of the regex examples. I should have just left it as it was since it was working. I am going to try and revert it to how it was. I shouldn't have tried to do everything at once, I should have just focused on finishing the tests.

## 23/09/2025 - Log #11

I have now finished rewriting all the old tests, and amazingly they all passed. There were initially many failures, but this was due to a typo in the benchmark function `words_to_length_from_regex`. I accidentally used `words_of_length` instead of `words_to_length` in the tuple comprehension, which resulted in most tuples being empty if the regex didn't match words of exactly that length. That has been fixed now. I also think I resolved the problem with brackets in the NFA edge labels, by simply trimming all brackets right before creating the NFA and *after* the elimination loop itself. This is a much cleaner solution than trying something complex in the loop itself, and I should've thought of it earlier. I was trying to be too clever, and 
probably overthinking the big-O performance by trying to minimise the number of passes over the edge labels. Anyway, now the task is to write some more tests for the other files, which shouldn't be too hard has most of the complex foundational logic is handled in the existing tests.

## 24/09/2025 - Log #12
I have written the tests for the NFA and DFA now (as opposed to the tests for the `Transition` objects). They work, but I have a constant feeling in the back of my mind that I am missing some obvious edge case that is crucial to test. However I think this feeling is inevitable and hopefully it means I am thinking in the right way and staying viligant. After all, if I could know for sure I hit all edge cases, then there would be no bugs anywhere, which is of course impossible. I think this is an inherent deficiency of human psychology - it is easy to think about the cases I know I've tested, but very hard to think of the ones I haven't caught. Try to not think of a pink elephant...

I had a very enlightening dicussion with somebody who worked in fincance today, that made me feel a lot better about the deficiencies of my tests. I had already heard stories of how complex banks' systems are, and how all of it is really held together by 'tape and string' despite the sleek exterior. First they had the original systems in the 70s, then they had to add a layer for ATMs, then for the internet, and so on. At each stage there is so much increasing complexity and compatibility concerns with the legacy code that it is virtually impossible for anybody to ensure that every single thing works with every 
other thing as it should do. As this person said, nobody knew that the internet would come along when they build the original systems, and how could they? This makes me think the term 'future-proofing' is somewhat self-contradictory - if you could really predict the future you wouldn't have to future proof, you could just write the code as it will be used. There is a joke that all of the worlds most important digital infrastructure is run from a single Excel spreadsheet, that was never intended for that purpose. It might be true that that joke has a kernel of truth to it. Anyway, I guess my point is that if the people that control all money in the world can admit they don't really know what they're doing when faced with such an intractable system, then I shouldn't worry too much about my silly little Python project. Nobody is going to wrongly default on their mortgage if a DFA accepts the wrong word.

## 10/10/2025 - Log #13
Well, the initial version of the project has been out on github for a couple weeks now, and it's been nice to take a break from autolang. I got a handful of testers to clone it, but I don't think anyone has had the time to look at it yet. It feels strange and exciting to have my code out on the web for the first time ever. The potential for greater public scrutiny is somewhat stressful, but at the end of the day nobody is going to be looking at it in great deal anyway.
Unfortunately my autolang retirement has been forced to a premature end, because I discovered a memory bug when generating words over an alphabet. I knew this was suboptimal and would have exponential explosion, but I naively assumed that either Python or the user OS would handle this safely. To my dismay, while I was testing in jupyter to see how the end-UX was, I tried to get the language of the example DFA for length 30, and my computer bluescreened. This really shouldn't have been surprising - computers are great because they do exactly what you tell them to do, even if that entails allocating several GB of memeory for a single list of strings. 
Fortunately this should be easy to fix, as since releasing v0.1.0 I have learned more about generators and iterators. The current `.L()` methods work by fetching the entire language upfront, and then sequentially running the DFA on each word. What needs to happen instead is giving the DFA an iterator object, so it only generates and stores the words one-by-one while it computes them, vastly improving the memory load. I do still want to retain the option of storing the whole language in a variable, as that could be useful later. But this will need an actual safety check from me - I can't rely on Python. Now I will have two types of alphabet for different uses - the current one and the more memory-safe generator versions. I think the best way to do this is with a wrapper that calls one or the other depending on an arg. But before I think about the rapidly complex-ifiying architecture, I need to just rewrite the alphabet functions in utils.py.
I said it was unfortunate I was pulled back into autolang, but that's not really true. This is very good, as it gives me an excuse to finally get the diagrams working. That is a whole other can of worms since I can't easily test matplotlib in the terminal, but that is next week's problem.

## 13/10/2025 - Log #14
The patch v0.1.1 is now finished and has been pushed to github. I'm pretty sure it has fixed the memory issue, and all of the tests still passed so everything is good. I was pleasantly surpised that I was able to implement the generators without really touching the downstream behaviour at all. I also took the oppertunity to add a generator mode to the `.L()` methods, as that could certainly be useful for processing languages later if they get very large, but it shouldn't be the default for users who just want to print the language. I thought about adding a runtime safety check at the automaton level as well, but this is more challenging: precomputing the language size of the whole set of words is easy, as it's just cominatorics; trying to precompute the number of accepted words is a lot harder as it will depend on the specific automaton - some can accept only a handful of words, while others accept all of them. I think the only way to do this without making some complex estimate is by straightforwardly running through the whole language, which is precisely what would be held off via the safety check. Therefore for now I will just trust that users are responsible enough to know about the long compute time if they give a big length. At least now the worst case is just hours of runtime, and not a system crash.
Now I'm finally ready to finish working on the transition diagrams. This was in progress way back at the start of the project in June(?), but I didn't get very far and paused development to work on the core logic, since visualising nice layouts will be tricky in general. This is the first time I'm using git branches, which is another exciting learning moment, but I'll have to be careful I do it right and merge correctly. git is such a powerful tool, but still quite complex to use for me. I have made a primary new branch for v0.2.0, and now plan to make another new branch for each added feature. Of course the largest such branch will be for transition diagrams, but there are other features I want to add now instead of v0.3.0. To me this seems to be continuing the trend of autolang being quite self-referential - first there was handling regex input and building transition tables, which natually invoked parsing and CFGs; now I'm rendering graphs, and I have to learn the tree-like structure of git commits. This is probably just coincidence - after all most mathematical ideas are similar to eachother if you squint hard enough - but I think its so interesting spotting these connections when doing a sort of 'meta' simulation project like this.
For the transition diagrams themselves, the overall logic will also be harder than I expected I think. Originally I was working in jupyter, which plots inline for easy testing and means you don't have to worry about the graphics in the backend. But now I'm working with the terminal, so matplotlib will not be able to plot directly here. The easiest solution I can think of is making a wrapper which defers to two different plotting modes - one that saves the plot as an image, and the other that plots inline for users who likely *will* be using jupyter. Either the specific mode will be passed directly, or I will try and auto-detect a GUI-backend to see if inline plotting is possible. I have no idea how to do this well, and I will probably have to sift through docs again. But anyway, I can leave this for now and just implement the 'save' mode so I can test the diagrams themselves.
The current plan is to use `networkx` to generate intermediate digraphs from the automata, and then pass this to `matplotlib` to actually render the figures. I have also seen `graphviz` mentioned a lot, along with other libraries, but that seems too complex to learn right now whilst I just get it working. Graph visualisation is such a deep rabbit hole and there are so many strategies, so I want to keep it simple for now, while retaining the option to swap out the rendering logic later if needs be. My understanding is that most Python graph libraries can use a `networkx` object to draw, so that can function as the core of the visualising feature, and the downstream drawing methods will take it from there. I want to prevent an explosion in layers of abstraction, but I think its important to keep everything quite modular here. Anyway, time to work on the new branch!